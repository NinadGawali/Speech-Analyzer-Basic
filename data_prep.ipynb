{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0f5ca3-572e-4b83-a170-96e5ab1f8506",
   "metadata": {},
   "source": [
    "# üìò Speech Analyzer: Data Ingestion and Vector Store Preparation\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## üìå Introduction\r\n",
    "\r\n",
    "This notebook documents the initial phase of the **Speech Analyzer** project. The goal is to collect speech data from the web, preprocess it, and prepare it for efficient semantic search using vector embeddings. We achieve this by web scraping speeches, splitting them into manageable chunks, and storing their vector representations in a **FAISS** database.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## üîπ 1. Web Scraping and Data Storage\r\n",
    "\r\n",
    "In this section, we use **BeautifulSoup (bs4)** to scrape textual data from a relevant website or HTML source. The scraped content is cleaned and structured before being stored in a **JSON format** for easy downstream processing.\r\n",
    "\r\n",
    "**Steps:**\r\n",
    "- Use `requests` to fetch the webpage content  \r\n",
    "- Parse HTML using `BeautifulSoup`  \r\n",
    "- Extract meaningful speech content  \r\n",
    "- Save the data in `data.json` format  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## üîπ 2. Data Splitting Using RecursiveCharacterTextSplitter\r\n",
    "\r\n",
    "To ensure semantic consistency while chunking the textual data, we use **RecursiveCharacterTextSplitter** from LangChain. This technique breaks the speech text into overlapping or non-overlapping chunks suitable for embedding.\r\n",
    "\r\n",
    "**Key Features:**\r\n",
    "- Maintains sentence structure where possible  \r\n",
    "- Handles large documents efficiently  \r\n",
    "- Outputs manageable text chunks for embeddings  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## üîπ 3. Embedding Creation and FAISS Vector Database Ingestion\r\n",
    "\r\n",
    "We convert each text chunk into a high-dimensional vector using a pre-trained **embedding model** (`Ollama`). These vectors are then stored in a **FAISS (Facebook AI Similarity Search)** vector database for efficient similarity search.\r\n",
    "\r\n",
    "**Tasks:**\r\n",
    "- Initialize the embedding model  \r\n",
    "- Transform text chunks to embeddings  \r\n",
    "- Push the vectors into FAISS  \r\n",
    "- Save the FAISS index for later use  \r\n",
    "\r\n",
    "---\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ed5fe-56f4-47f8-be89-0bed51a51e93",
   "metadata": {},
   "source": [
    "## üßæ Imports and Setup\r\n",
    "\r\n",
    "In this section, we import all the necessary libraries and modules required for the workflow of the Speech Analyzer project:\r\n",
    "\r\n",
    "- **`requests`** and **`BeautifulSoup`**: For scraping and parsing HTML content from the web.\r\n",
    "- **`json`** and **`os`**: For handling JSON file operations and managing file paths.\r\n",
    "- **`RecursiveCharacterTextSplitter`**: From LangChain, used to split long texts into semantically meaningful chunks.\r\n",
    "- **`FAISS`**: A high-performance vector store from the LangChain community module, used for storing and querying vector embeddings.\r\n",
    "- **`OllamaEmbeddings`**: A pre-trained embedding model used to convert text into vector representations.\r\n",
    "- **`Document`**: A utility class from LangChain used to create standardized document objects for downstream processing.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c164f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.docstore.document import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3c87bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"vectorstore\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e332d-c5d2-4c47-b0ba-8a9e937f687e",
   "metadata": {},
   "source": [
    "## üåê Web Scraping Famous Persuasive Speeches\r\n",
    "\r\n",
    "In this section, we scrape persuasive speech content from the website [HighSpark](https://highspark.co/famous-persuasive-speeches/) using `requests` and `BeautifulSoup`. The data is then structured and stored in a JSON file for further processing.\r\n",
    "\r\n",
    "### üîÑ Steps Involved:\r\n",
    "\r\n",
    "1. **Fetch the Webpage Content**\r\n",
    "   - The URL of the page containing famous persuasive speeches is stored in the variable `url`.\r\n",
    "   - The `requests.get()` function is used to retrieve the HTML content of the page.\r\n",
    "   - The HTML is parsed using `BeautifulSoup` with the `html.parser`.\r\n",
    "\r\n",
    "2. **Extracting Speech Data**\r\n",
    "   - The loop `for h2 in soup.find_all(\"h2\")` iterates over all `<h2>` tags which generally hold the speech titles.\r\n",
    "   - For each `<h2>`, the following elements are extracted:\r\n",
    "     - **Title**: The text inside the `<h2>` tag.\r\n",
    "     - **Speech Content**: The next `<blockquote>` tag after the `<h2>` is assumed to contain the actual speech.\r\n",
    "     - **Background Information**: If available, the paragraph `<p>` immediately after the `<blockquote>` is extracted as background or context for the speech.\r\n",
    "   - If both the speech and optional background exist, they are added to a list `speeches` as dictionaries with `title`, `text`, and `background`.\r\n",
    "\r\n",
    "3. **Storing the Data**\r\n",
    "   - The `speeches` list is saved in JSON format to a file named `speeches.json` inside a `data/` directory.\r\n",
    "   - The JSON is formatted with indentation for better readability using `json.dump(..., indent=2)`.\r\n",
    "\r\n",
    "4. **Logging**\r\n",
    "   - A simple print statement displays how many speeches were successfully scraped and saved.\r\n",
    "\r\n",
    "> ‚úÖ After this step, we have a clean and structured dataset of famous persuasive speeches ready for chunking and embedding.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256de960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 40 speeches.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://highspark.co/famous-persuasive-speeches/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "speeches = []\n",
    "\n",
    "for h2 in soup.find_all(\"h2\"):\n",
    "    title = h2.get_text(strip=True)\n",
    "    blockquote = h2.find_next(\"blockquote\")\n",
    "    background_p = blockquote.find_next(\"p\") if blockquote else None\n",
    "\n",
    "    if blockquote:\n",
    "        speech_text = blockquote.get_text(strip=True)\n",
    "        background = background_p.get_text(strip=True) if background_p else \"\"\n",
    "        speeches.append({\n",
    "            \"title\": title,\n",
    "            \"text\": speech_text,\n",
    "            \"background\": background\n",
    "        })\n",
    "\n",
    "with open(\"data/speeches.json\", \"w\") as f:\n",
    "    json.dump(speeches, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(speeches)} speeches.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998cdaef-68d5-4d68-a6c6-50dc7ddf49ab",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Splitting Speech Data into Chunks with Metadata\n",
    "\n",
    "After scraping and saving the speeches, we now proceed to **load the JSON data** and **split the speech content into smaller chunks** using LangChain‚Äôs `RecursiveCharacterTextSplitter`. These chunks are then wrapped into `Document` objects along with relevant metadata.\n",
    "\n",
    "### üìÇ Step-by-Step Breakdown:\n",
    "\n",
    "1. **Load the JSON Data**\n",
    "   - The file `data/speeches.json` is opened and read using `json.load()`.\n",
    "   - The result is a list of speech dictionaries, each containing `title`, `text`, and `background`.\n",
    "\n",
    "2. **Initialize Text Splitter**\n",
    "   - We use `RecursiveCharacterTextSplitter` with the following parameters:\n",
    "     - `chunk_size=500`: Each chunk will contain up to 500 characters.\n",
    "     - `chunk_overlap=100`: Chunks will overlap by 100 characters to maintain context continuity.\n",
    "   - This ensures that chunks are semantically meaningful and do not cut off in the middle of sentences unnecessarily.\n",
    "\n",
    "3. **Prepare Chunks with Metadata**\n",
    "   - For each speech in the list:\n",
    "     - Combine the speech body and background information into one string (`full_text`).\n",
    "     - Use the `splitter` to divide the `full_text` into smaller segments.\n",
    "     - For each resulting chunk:\n",
    "       - Create a `Document` object with:\n",
    "         - `page_content`: the chunked text.\n",
    "         - `metadata`: a dictionary containing the `title` of the speech.\n",
    "     - All `Document` objects are stored in the `documents` list.\n",
    "\n",
    "This prepares the dataset in a format that is compatible with vector embedding models and vector databases like FAISS, while preserving context and metadata for traceability.\n",
    "\n",
    "> ‚úÖ Result: A list of text chunks with associated metadata, ready to be embedded and stored in a vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e136c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/speeches.json\") as f:\n",
    "    speeches = json.load(f)\n",
    "\n",
    "documents = []\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "for speech in speeches:\n",
    "    full_text = f\"{speech['text']}\\n\\nBackground:\\n{speech['background']}\"\n",
    "    chunks = splitter.split_text(full_text)\n",
    "    for chunk in chunks:\n",
    "        documents.append(Document(page_content=chunk, metadata={\"title\": speech[\"title\"]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383deaf6-6d4e-4e30-a317-ae86dab975ea",
   "metadata": {},
   "source": [
    "## üß† Creating and Saving FAISS Vector Store using Ollama Mistral Embeddings\n",
    "\n",
    "In this final step, we embed the chunked documents and store them in a **FAISS vector database** for efficient similarity search. We use the **Ollama Mistral** model to generate high-dimensional vector representations for each chunk.\n",
    "\n",
    "### üõ†Ô∏è Step-by-Step Explanation:\n",
    "\n",
    "1. **Initialize Embedding Model**\n",
    "   - We use `OllamaEmbeddings` with the model name `\"mistral\"`.\n",
    "   - This model runs **locally**, so it may consume significant compute resources and take time to generate embeddings depending on your system.\n",
    "\n",
    "2. **Create FAISS Vector Store**\n",
    "   - We build the FAISS index using `FAISS.from_documents()`, which:\n",
    "     - Passes each chunked `Document` through the embedding model.\n",
    "     - Stores the resulting vectors in an efficient FAISS index structure.\n",
    "\n",
    "3. **Save FAISS Index Locally**\n",
    "   - The index is saved to a local directory `vectorstore/faiss_index` using `db.save_local()` so it can be reloaded later without recomputing embeddings.\n",
    "\n",
    "4. **Print Confirmation**\n",
    "   - A simple message is printed once the process completes.\n",
    "\n",
    "> ‚ö†Ô∏è **Note**: This cell may take a significant amount of time to run, especially if the Mistral model is being initialized for the first time or if many documents are being processed. Ensure sufficient CPU/GPU resources are available when running this step.\n",
    "\n",
    "> ‚úÖ After this step, we have a persistent, searchable vector store containing all the embedded chunks of the speech data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3c78b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JCIN\\AppData\\Local\\Temp\\ipykernel_7432\\2370184254.py:5: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding = OllamaEmbeddings(model=\"mistral\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Initialize Ollama Mistral embedding\n",
    "embedding = OllamaEmbeddings(model=\"mistral\")\n",
    "\n",
    "# Build FAISS vector store from documents\n",
    "db = FAISS.from_documents(documents, embedding)\n",
    "\n",
    "# Save vector store locally\n",
    "db.save_local(\"vectorstore/faiss_index\")\n",
    "\n",
    "print(\"Vector store created and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1064283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 30. Black Power Address at UC Berkeley by Stokely Carmichael\n",
      "Content: to sanction Black Power. We‚Äôre tired waiting; every time black people move in this country, they‚Äôre forced to defend their position before they move. It‚Äôs time that the people who are supposed to be defending their position do that. That‚Äôs white people. They ought to start defending themselves as to why they have oppressed and exploited us.‚Äù\n",
      "\n",
      "Score: 133587.265625\n",
      "\n",
      "Title: 35. Questioning the Universe by Stephen Hawking\n",
      "Content: show that we have made remarkable progress in the last hundred years. But if we want to continue beyond the next hundred years, our future is in space. That is why I am in favor of manned ‚Äî or should I say, personned ‚Äî space flight.‚Äù\n",
      "\n",
      "Score: 135536.296875\n",
      "\n",
      "Title: 21. June 9 Speech to Martial Law Units by Deng Xiaoping\n",
      "Content: Perhaps this bad thing will enable us to go ahead with reform and the open policy at a steadier and better ‚Äî even a faster ‚Äî pace, more speedily correct our mistakes, and better develop our strong points.‚Äù\n",
      "\n",
      "Score: 136037.03125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What did Queen Elizabeth I say about her role in the war against Spain?\"\n",
    "results = db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "for doc, score in results:\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Content: {doc.page_content}\\n\")\n",
    "    print(f\"Score: {score}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b9440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
